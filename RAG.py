import numpy as np
import requests
import faiss
import streamlit as st
import pickle
from typing import List, Dict, Any
import time
import json

class PersianRAGSystem:
    """Ø³ÛŒØ³ØªÙ… RAG Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ API Jina"""
    
    def __init__(self, jina_api_key: str):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø³ÛŒØ³ØªÙ… RAG"""
        
        if not jina_api_key:
            raise ValueError("âŒ API Key Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø§Ø³Øª")
            
        self.jina_api_key = jina_api_key
        self.api_url = "https://api.jina.ai/v1/embeddings"
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
        self.chunks = []
        self.embeddings = None
        self.vector_index = None
        self.chunk_metadata = []
        
        st.write("âœ… Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø§ API Jina Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø´Ø¯")
        st.write(f"ğŸŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡: ÙØ§Ø±Ø³ÛŒØŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ø¹Ø±Ø¨ÛŒ")

    def _call_jina_api(self, texts: List[str], task: str = "retrieval.passage") -> List[List[float]]:
        """ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API Jina Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ embeddings"""
        
        headers = {
        'Content-Type': 'application/json',  # âœ… ØªØºÛŒÛŒØ± Ø¨Ù‡ single quote
        'Authorization': f'Bearer jina_f79a39580af2409c9192df3695351ff6-Up2UwFsKAGW1Az1UoKfK2-bJGzA'  # âœ… ØªØºÛŒÛŒØ± Ø¨Ù‡ single quote
        }
        
        embeddings = []
        batch_size = 10  # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            data = {
                "model": "jina-embeddings-v3",
                "task": task,
                "input": texts,
            }
            
            try:
                response = requests.post(self.api_url, headers=headers, json=data)
                response.raise_for_status()
                
                result = response.json()
                for item in result["data"]:
                    embeddings.append(item["embedding"])
                    
                # ØªØ§Ø®ÛŒØ± Ú©ÙˆØªØ§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² rate limiting
                time.sleep(0.1)
                
            except requests.exceptions.RequestException as e:
                st.write(f"âŒ Ø®Ø·Ø§ Ø¯Ø± API call: {e}")
                raise
        
        return embeddings

    def create_embeddings(self, chunks: List[str]) -> np.ndarray:
        """ØªØ¨Ø¯ÛŒÙ„ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ embedding"""
        
        st.write(f"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ embeddings Ø¨Ø±Ø§ÛŒ {len(chunks)} Ú†Ø§Ù†Ú©...")
        
        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API Jina
        embeddings_list = self._call_jina_api(chunks, task="retrieval.passage")
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numpy array
        embeddings = np.array(embeddings_list, dtype=np.float32)
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        embeddings = embeddings / norms
        
        st.write(f"âœ… ØªÙˆÙ„ÛŒØ¯ embeddings Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
        st.write(f"ğŸ“ Ø§Ø¨Ø¹Ø§Ø¯ Ù‡Ø± embedding: {embeddings.shape[1]}")
        
        return embeddings

    def build_vector_index(self, embeddings: np.ndarray):
        """Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ FAISS Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹"""
        
        st.write("ğŸ—ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø¯Ø§Ø±ÛŒ...")
        
        dimension = embeddings.shape[1]
        
        if len(embeddings) < 1000:
            self.vector_index = faiss.IndexFlatIP(dimension)
        else:
            nlist = min(100, len(embeddings) // 10)
            quantizer = faiss.IndexFlatIP(dimension)
            self.vector_index = faiss.IndexIVFFlat(quantizer, dimension, nlist)
            self.vector_index.train(embeddings)
        
        self.vector_index.add(embeddings)
        st.write(f"âœ… Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯: {self.vector_index.ntotal} Ø¨Ø±Ø¯Ø§Ø±")

    def add_documents(self, chunks: List[str]):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø³Ù†Ø§Ø¯ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… RAG"""
        
        self.chunks = chunks
        
        self.chunk_metadata = [
            {
                'chunk_id': i,
                'length': len(chunk),
                'preview': chunk[:100] + "..." if len(chunk) > 100 else chunk
            }
            for i, chunk in enumerate(chunks)
        ]
        
        self.embeddings = self.create_embeddings(chunks)
        self.build_vector_index(self.embeddings)
        
        st.write(f"ğŸ¯ {len(chunks)} Ø³Ù†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")

    def search_similar_chunks(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„"""
        
        if self.vector_index is None:
            raise ValueError("âŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯")
        
        st.write(f"ğŸ” Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: {query[:50]}...")
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø³ÙˆØ§Ù„ Ø¨Ù‡ embedding Ø§Ø² Ø·Ø±ÛŒÙ‚ API
        query_embeddings_list = self._call_jina_api([query], task="retrieval.passage")  # âœ… ØªØºÛŒÛŒØ± task
        query_embedding = np.array(query_embeddings_list, dtype=np.float32)
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        norm = np.linalg.norm(query_embedding)
        query_embedding = query_embedding / norm
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø§ÛŒÙ†Ø¯Ú©Ø³
        scores, indices = self.vector_index.search(query_embedding, top_k)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx >= 0:
                results.append({
                    'rank': i + 1,
                    'chunk_id': idx,
                    'similarity_score': float(score),
                    'text': self.chunks[idx],
                    'metadata': self.chunk_metadata[idx]
                })
        
        st.write(f"âœ… {len(results)} Ù†ØªÛŒØ¬Ù‡ Ù…Ø±ØªØ¨Ø· ÛŒØ§ÙØª Ø´Ø¯")
        return results

    def save_system(self, filepath: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø¬Ø¯Ø¯"""
        
        system_data = {
            'chunks': self.chunks,
            'embeddings': self.embeddings.tolist() if self.embeddings is not None else None,
            'chunk_metadata': self.chunk_metadata
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(system_data, f)
        
        if self.vector_index is not None:
            faiss.write_index(self.vector_index, filepath.replace('.pkl', '.faiss'))
        
        st.write(f"ğŸ’¾ Ø³ÛŒØ³ØªÙ… Ø¯Ø± {filepath} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

    def load_system(self, filepath: str):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ… RAG Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡"""
        
        with open(filepath, 'rb') as f:
            system_data = pickle.load(f)
        
        self.chunks = system_data['chunks']
        self.chunk_metadata = system_data['chunk_metadata']
        
        if system_data['embeddings']:
            self.embeddings = np.array(system_data['embeddings'], dtype=np.float32)
            
        faiss_path = filepath.replace('.pkl', '.faiss')
        try:
            self.vector_index = faiss.read_index(faiss_path)
            st.write(f"ğŸ“‚ Ø³ÛŒØ³ØªÙ… Ø§Ø² {filepath} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
        except:
            st.write("âš ï¸ ÙØ§ÛŒÙ„ Ø§ÛŒÙ†Ø¯Ú©Ø³ ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù…Ø¬Ø¯Ø¯ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯...")
            if self.embeddings is not None:
                self.build_vector_index(self.embeddings)